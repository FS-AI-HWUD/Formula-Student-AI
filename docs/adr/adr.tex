\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{bm}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Autonomous Design Report FS-AI\\[-0.3em]
{\Large Atlas Racing - Heriot Watt University Dubai}\\[-0.6em]
}

\author{\IEEEauthorblockN{Joseph Abdo, Moaiz Saeed, Aditya Shibu, Abdul Maajid Aga and Apsara Sivaprazad}
}

\maketitle

\begin{abstract}
Autonomous racing presents unique perception challenges that demand high-precision environmental sensing with minimal latency. This Autonomous Design report documents our technical approach to developing a fully autonomous vehicle for the FS-AI UK competition. A key challenge we face is the unavailability of the ADS-DV vehicle in our home country, the UAE, which significantly limits our ability to test on the given hardware. As a result, all our systems are designed to be robust, modular, and adaptable, allowing for rapid iteration. For instance, we have implemented fallback pipelines to ensure we can at least showcase a functioning autonomous system under unforeseen conditions.
\end{abstract}

\section{Introduction}
This document is a model and instructions for \LaTeX.
Please observe the conference page limits. 

\section{System Architecture}

\subsection{Maintaining the Integrity of the Specifications}

The IEEEtran class file is used to format your paper and style the text. All margins, 
column widths, line spaces, and text fonts are prescribed; please do not 
alter them. You may note peculiarities. For example, the head margin
measures proportionately more than is customary. This measurement
and others are deliberate, using specifications that anticipate your paper
as one part of the entire proceedings, and not as an independent document. 
Please do not revise any of the current designations.

\section{Perception}
This section details the implementation of the vehicle's perception system - explaining how it interprets its environment using both LiDAR (laser-based) and vision-based technologies.

\subsection{LiDAR (laser-based)}\label{AA}
We have selected the RoboSense Helios series LiDAR with 16-beam configuration, offering a balanced trade-off between angular resolution, detection range, update rate, and cost-effectiveness. To enhance data reliability, we applied filtering and clustering techniques to remove irrelevant or noisy points that could interfere with path planning. Our code detection pipeline using LiDAR follows a multistage approach, as outlined below:
\subsubsection{Raw Data Acquisition}
Data is captured as points in 3D space and transformed to the vehicle's reference frame using sensor\_transform matrices. We've then implemented a thread-based processing with MutEx (Mutually Exclusive) locks to ensure thread safety while maintaining real-time performance.
\subsubsection{Point Cloud Filtering and Accumulation}
We employ several filtering strategies:
\begin{itemize}
    \item Distance-based filtering:
    \[
    \mathit{close\_points\_mask} = \left( d < 50.0 \right)
    \]
    where \textbf{‘d’} is the distance to each point. This step filters out all points beyond 50 meters, allowing the system to focus on relevant track sections.

    \item Height-based filtering:
    \[
    \mathit{near\_ground\_mask} = \left( z < h_{\text{ground}} + 0.5 \right) \land \left( z > h_{\text{ground}} \right)
    \]
    where \textbf{‘z’} is the z-coordinate of the LiDAR points, and \textbf{‘$\bm{h_{\text{ground}}}$’} denotes the estimated ground height.

    \item Point accumulation: Points from multiple frames are appended to improve cone detection density, especially in sparse or occluded regions.
\end{itemize}

\subsubsection{Cone Identification}
Our approach uses DBSCAN clustering with the parameters eps=0.5 and min\_samples=5, we found this to be the sweet spot which gave a good balance between noise reduction and the ability to detect distinct clusters in our data points. We selected DBSCAN over alternatives such as OPTICS because DBSCAN offers better computational efficiency at O(n log n) vs. O(n\textsuperscript{2}) which is critical for real-time performance. Although OPTICS provides more flexibility, since such granularity was unnecessary in our context where cones are relatively uniform in size and spacing, DBSCAN effectively filters out noise while reliably clustering actual cone detections.

\vspace{0.2em}
\subsubsection{Cone Validation}
We validate detected cones through size validation, ensuring that each cluster matches the expected physical dimensions of a cone. This is followed by confidence scoring, which evaluates point density and other cluster characteristics. Additionally, we have implemented multi-frame tracking to reduce false positives and enhance detection stability over time.

\vspace{0.4em}
This LiDAR processing system maintains deterministic processing times below 100ms through efficient filtering and use of optimized algorithms such as DBSCAN. We've implemented 3D visualization capabilities using both Open3D and ROS visualization markers for real-time debugging and development.

\subsection{Image and Object Detection (vision-based)}
Our object detection system is designed to accurately identify and classify the track cones in real-time while providing precise spatial information for navigation. After going through several approaches, we selected YOLOv8 as our primary detection model.

\subsubsection{Model Development and Training}
Utilizing three cone datasets from Kaggle, we created a unified training dataset with standardized labeling conventions. Our classification scheme used numeric labels (0=orange, 1=yellow, 2=blue, 3=large orange, and 4=unknown) to ensure consistent identification across various racing environments. The training process involved a train-test split of 80\% (10,003 images) 20\% (10\% validation, and 10\% testing, 1,250 images each) along with a training configuration with 100 epochs, 32 batches and early stopping patience of 25. 

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.055]{confusionmatrix.png}}
\caption{Confusion Matrix of our trained YOLO Model}
\label{fig}
\end{figure}

\textbf{Testing Result:} Our model achieved excelled detection performance as shown in Figure 3.1, with particularly strong results for yellow cones (highest actual positive rate) and blue cones. The confusion matrices revealed that most misclassifications occurred between visually similar cone types.

\subsubsection{YOLOv8 vs. HOG Performance Analysis}
We conducted a comparative analysis between YOLO and Histogram of Oriented Gradients (HOG) with Support Vector Machines (SVMs), referencing Kaplan and Şaykol's research. While HOG with SVM achieved an 86.7\% success rate when trained on 80\% of the dataset, YOLO demonstrated superior reliability and accuracy in racing environments with

\subsection{Depth Camera (vision-based)}
Our system utilizes the ZED 2i stereo camera as a secondary perception pipeline to enhance system reliability through sensor fusion and to provide critical color classification capabilities that complement our LiDAR system. We selected the ZED 2i specifically for its built-in stereo capabilities that provide accurate depth measurements up to 20m, critical for our cone detection requirements. The camera subsystem consists of two primary components.

\subsubsection{Advanced Depth Estimation}
A key innovation in our system is a multi-faceted depth estimation approach that combines several techniques: direct depth sampling from the stereo camera's depth map, temporal smoothing using a sliding window of recent detections, position-based depth estimation, and box-size–normalized depth correction. The final depth is computed as:
\[
\textit{final\_depth} = 0.5 \cdot \textit{smoothed\_depth} + 0.5 \cdot \textit{position\_depth}
\]
This provides more reliable depth estimates than any single method alone. This approach is particularly effective at handling the rapidly changing distances encountered in racing scenarios.

\subsubsection{Track Boundary Visualization}
Our system automatically identifies and visualizes track boundaries by first classifying detected cones based on color (yellow, blue, and orange). The cones are then sorted by depth to determine their sequential order along the track. To form a visual representation of the track edges, lines are drawn between consecutive cones of the same color. This process provides clear visual feedback that supports both real-time path planning and offline validation, helping to ensure accurate and reliable vehicle navigation.

\vspace{0.4em}
Through extensive testing, we found this camera-based perception system achieves detection ranges of 1-20m with centimeter-level accuracy after calibration. The integration with our LiDAR system through sensor fusion not only improves overall detection reliability but also color-based cone detection that simplifies our path planning algorithm.

\subsection{Equations}
Number equations consecutively. To make your 
equations more compact, you may use the solidus (~/~), the exp function, or 
appropriate exponents. Italicize Roman symbols for quantities and variables, 
but not Greek symbols. Use a long dash rather than a hyphen for a minus 
sign. Punctuate equations with commas or periods when they are part of a 
sentence, as in:
\begin{equation}
a+b=\gamma\label{eq}
\end{equation}

Be sure that the 
symbols in your equation have been defined before or immediately following 
the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
the beginning of a sentence: ``Equation \eqref{eq} is . . .''

\subsection{\LaTeX-Specific Advice}

Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
of ``hard'' references (e.g., \verb|(1)|). That will make it possible
to combine sections, add equations, or change the order of figures or
citations without having to go through the file line by line.

Please don't use the \verb|{eqnarray}| equation environment. Use
\verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
environment leaves unsightly spaces around relation symbols.

Please note that the \verb|{subequations}| environment in {\LaTeX}
will increment the main equation counter even when there are no
equation numbers displayed. If you forget that, you might write an
article in which the equation numbers skip from (17) to (20), causing
the copy editors to wonder if you've discovered a new method of
counting.

{\BibTeX} does not work by magic. It doesn't get the bibliographic
data from thin air but from .bib files. If you use {\BibTeX} to produce a
bibliography you must send the .bib files. 

{\LaTeX} can't read your mind. If you assign the same label to a
subsubsection and a table, you might find that Table I has been cross
referenced as Table IV-B3. 

{\LaTeX} does not have precognitive abilities. If you put a
\verb|\label| command before the command that updates the counter it's
supposed to be using, the label will pick up the last counter to be
cross referenced instead. In particular, a \verb|\label| command
should not go before the caption of a figure or a table.

Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
will not stop equation numbers inside \verb|{array}| (there won't be
any anyway) and it might stop a wanted equation number in the
surrounding equation.

\subsection{Some Common Mistakes}\label{SCM}
\begin{itemize}
\item The word ``data'' is plural, not singular.
\item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
\item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
\item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
\item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
\item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
\item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
\item Do not confuse ``imply'' and ``infer''.
\item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
\item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
\item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
\end{itemize}
An excellent style manual for science writers is \cite{b7}.

\subsection{Authors and Affiliations}
\textbf{The class file is designed for, but not limited to, six authors.} A 
minimum of one author is required for all conference articles. Author names 
should be listed starting from left to right and then moving down to the 
next line. This is the author sequence that will be used in future citations 
and by indexing services. Names should not be listed in columns nor group by 
affiliation. Please keep your affiliations as succinct as possible (for 
example, do not differentiate among departments of the same organization).

\subsection{Identify the Headings}
Headings, or heads, are organizational devices that guide the reader through 
your paper. There are two types: component heads and text heads.

Component heads identify the different components of your paper and are not 
topically subordinate to each other. Examples include Acknowledgments and 
References and, for these, the correct style to use is ``Heading 5''. Use 
``figure caption'' for your Figure captions, and ``table head'' for your 
table title. Run-in heads, such as ``Abstract'', will require you to apply a 
style (in this case, italic) in addition to the style provided by the drop 
down menu to differentiate the head from the text.

Text heads organize the topics on a relational, hierarchical basis. For 
example, the paper title is the primary text head because all subsequent 
material relates and elaborates on this one topic. If there are two or more 
sub-topics, the next level head (uppercase Roman numerals) should be used 
and, conversely, if there are not at least two sub-topics, then no subheads 
should be introduced.

\subsection{Figures and Tables}
\paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
bottom of columns. Avoid placing them in the middle of columns. Large 
figures and tables may span across both columns. Figure captions should be 
below the figures; table heads should appear above the tables. Insert 
figures and tables after they are cited in the text. Use the abbreviation 
``Fig.~\ref{fig}'', even at the beginning of a sentence.

\begin{table}[htbp]
\caption{Table Type Styles}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
\cline{2-4} 
\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
\hline
copy& More table copy$^{\mathrm{a}}$& &  \\
\hline
\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
\end{tabular}
\label{tab1}
\end{center}
\end{table}

\begin{figure}[htbp]
\centerline{\includegraphics{fig1.png}}
\caption{Example of a figure caption.}
\label{fig}
\end{figure}

Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
rather than symbols or abbreviations when writing Figure axis labels to 
avoid confusing the reader. As an example, write the quantity 
``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
units in the label, present them within parentheses. Do not label axes only 
with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
\{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
quantities and units. For example, write ``Temperature (K)'', not 
``Temperature/K''.

\section*{Acknowledgment}

The preferred spelling of the word ``acknowledgment'' in America is without 
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
acknowledgments in the unnumbered footnote on the first page.

\section*{References}

Please number citations consecutively within brackets \cite{b1}. The 
sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

Number footnotes separately in superscripts. Place the actual footnote at 
the bottom of the column in which it was cited. Do not put footnotes in the 
abstract or reference list. Use letters for table footnotes.

Unless there are six authors or more give all authors' names; do not use 
``et al.''. Papers that have not been published, even if they have been 
submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
Capitalize only the first word in a paper title, except for proper nouns and 
element symbols.

For papers published in translation journals, please give the English 
citation first, followed by the original foreign-language citation \cite{b6}.

\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
\end{thebibliography}
\vspace{12pt}
\color{red}
IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}